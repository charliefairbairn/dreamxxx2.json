{
  "input": {
    "workflow": {
      "3": {
        "inputs": {
          "seed": 1060584353809042,
          "steps": 20,
          "cfg": 2.5,
          "sampler_name": "euler",
          "scheduler": "simple",
          "denoise": 1,
          "model": [
            "81",
            0
          ],
          "positive": [
            "6",
            0
          ],
          "negative": [
            "7",
            0
          ],
          "latent_image": [
            "58",
            0
          ]
        },
        "class_type": "KSampler",
        "_meta": {
          "title": "KSampler"
        }
      },
      "6": {
        "inputs": {
          "text": "1girl, nude, solo, ginger, long hair, perfect face, perfect eyes, female pubic hair, sexy, perfect body, standing, ubuttoned shirt covering her nipples, cleavage, seductive look, looking at the camera, pulling down pink panties, panties down, no panties, leaning forward, perfect hands, perfect breasts, blushing, super cute, close up, dynamic angle\ndr3am",
          "clip": [
            "38",
            0
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Positive Prompt)"
        }
      },
      "7": {
        "inputs": {
          "text": "bad anatomy, defoemd. ",
          "clip": [
            "38",
            0
          ]
        },
        "class_type": "CLIPTextEncode",
        "_meta": {
          "title": "CLIP Text Encode (Negative Prompt)"
        }
      },
      "8": {
        "inputs": {
          "samples": [
            "3",
            0
          ],
          "vae": [
            "39",
            0
          ]
        },
        "class_type": "VAEDecode",
        "_meta": {
          "title": "VAEDecode"
        }
      },
      "37": {
        "inputs": {
          "filename": "qwen_image_fp8_e4m3fn.safetensors"
        },
        "class_type": "UNETLoader",
        "_meta": {
          "title": "UNETLoader"
        }
      },
      "38": {
        "inputs": {
          "filename": "qwen_2.5_vl_7b_fp8_scaled.safetensors"
        },
        "class_type": "CLIPLoader",
        "_meta": {
          "title": "CLIPLoader"
        }
      },
      "39": {
        "inputs": {
          "filename": "qwen_image_vae.safetensors"
        },
        "class_type": "VAELoader",
        "_meta": {
          "title": "VAELoader"
        }
      },
      "58": {
        "inputs": {
          "width": 512,
          "height": 512,
          "batch_size": 1
        },
        "class_type": "EmptySD3LatentImage",
        "_meta": {
          "title": "EmptySD3LatentImage"
        }
      },
      "60": {
        "inputs": {
          "filename_prefix": "Qwen/qwen",
          "images": [
            "8",
            0
          ]
        },
        "class_type": "SaveImage",
        "_meta": {
          "title": "SaveImage"
        }
      },
      "66": {
        "inputs": {
          "value": 3.1
        },
        "class_type": "ModelSamplingAuraFlow",
        "_meta": {
          "title": "ModelSamplingAuraFlow"
        }
      },
      "73": {
        "inputs": {
          "filename": "Qwen-Image-Lightning-8steps-V1.0.safetensors",
          "model": [
            "37",
            0
          ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
          "title": "LoraLoaderModelOnly"
        }
      },
      "75": {
        "inputs": {
          "filename": "Qwen_Real_Nud3s.safetensors",
          "model": [
            "76",
            0
          ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
          "title": "LoraLoaderModelOnly"
        }
      },
      "76": {
        "inputs": {
          "filename": "Qwen-MysticXXX-v1.safetensors",
          "model": [
            "73",
            0
          ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
          "title": "LoraLoaderModelOnly"
        }
      },
      "77": {
        "inputs": {
          "filename": "qwen_dr3am.safetensors",
          "model": [
            "75",
            0
          ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
          "title": "LoraLoaderModelOnly"
        }
      },
      "81": {
        "inputs": {
          "filename": "quicktake150style_qwen.safetensors",
          "model": [
            "77",
            0
          ]
        },
        "class_type": "LoraLoaderModelOnly",
        "_meta": {
          "title": "LoraLoaderModelOnly"
        }
      }
    }
  }
}